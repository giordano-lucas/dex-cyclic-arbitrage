{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:01:59.181394: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/scratch/izar/kapps/DEX-Cyclic-Arbitrage/\")\n",
    "from config.get import cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform `tokens` into dummy variables (one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform tokens into dummies\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "token_columns = list(filter(lambda c: c.startswith('token'),log_data.columns))\n",
    "def one_hot_tokens():\n",
    "    one_enc = OneHotEncoder(sparse=False) \n",
    "    unique_tokens = np.unique(pd.concat([log_data[token] for token in token_columns],axis=0))\n",
    "    one_enc.fit(unique_tokens.reshape(-1, 1))\n",
    "    # transform\n",
    "    encode = lambda col: one_enc.transform(log_data[col].to_numpy().reshape(-1, 1))\n",
    "    # encode and convert as dataframes\n",
    "    \n",
    "    encoded = [pd.DataFrame(encode(token)).add_prefix(f\"token_{key}_\") for key,token in enumerate(token_columns)]\n",
    "    return pd.concat(encoded, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15373/3440479160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mone_hot_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15373/2903111306.py\u001b[0m in \u001b[0;36mone_hot_tokens\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_hot_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mone_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0munique_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlog_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mone_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = pd.concat([log_data.drop(columns=token_columns),one_hot_tokens()], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Transform each cycle into a feature matrix  & Zero-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(cfg['files'][\"raw_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train/test split and standard scaling \n",
    "test_size = 0.3\n",
    "N =  X.shape[0]\n",
    "N_train = int(N * (1 - test_size))\n",
    "X_train, X_test, train_id, test_id = train_test_split(X, np.arange(X.shape[0]),test_size=test_size, random_state=123)\n",
    "\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "\n",
    "#X_train_scaled = scaler.transform(X_train)\n",
    "#X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(cfg['files']['raw_test_features'] , X_test)\n",
    "np.save(cfg['files']['raw_train_features'] ,X_train)\n",
    "np.save(cfg['files']['raw_test_ids'] , test_id)\n",
    "np.save(cfg['files']['raw_train_ids'] , train_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = keras.Input(shape=(3,600, 2))\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((3, 3), padding='same')(x)\n",
    "    x = layers.Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    encoded = layers.Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
    "    # at this point the representation is 100-dimensional\n",
    "    x = layers.Conv2D(4, (2, 2), activation='relu', padding='same')(encoded)\n",
    "    x = layers.UpSampling2D((1, 2))(x)\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((3, 3))(x)\n",
    "    decoded = layers.Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    autoencoder = keras.Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', metrics=['accuracy'],loss='mean_squared_error',)\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:02:20.413863: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-21 15:02:20.625999: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-12-21 15:02:20.626040: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (izar): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3, 600, 2)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 3, 600, 8)         152       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 200, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 200, 4)         292       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 100, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 100, 1)         17        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 100, 4)         20        \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 1, 200, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 200, 8)         296       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 3, 600, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 600, 2)         146       \n",
      "=================================================================\n",
      "Total params: 923\n",
      "Trainable params: 923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = build_model()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/90 [==============================] - 10s 117ms/step - loss: 54098.7344 - accuracy: 0.8029\n",
      "Epoch 2/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 36887.2656 - accuracy: 0.8141\n",
      "Epoch 3/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 35729.7266 - accuracy: 0.8141\n",
      "Epoch 4/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 35427.8008 - accuracy: 0.8141\n",
      "Epoch 5/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 35287.6328 - accuracy: 0.8141\n",
      "Epoch 6/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 35187.2227 - accuracy: 0.8141\n",
      "Epoch 7/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 35129.7500 - accuracy: 0.8141\n",
      "Epoch 8/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 35063.3984 - accuracy: 0.8141\n",
      "Epoch 9/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 35020.9531 - accuracy: 0.8141\n",
      "Epoch 10/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 34985.0508 - accuracy: 0.8141\n",
      "Epoch 11/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34933.6602 - accuracy: 0.8141\n",
      "Epoch 12/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 34886.0312 - accuracy: 0.8141\n",
      "Epoch 13/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34840.4531 - accuracy: 0.8141\n",
      "Epoch 14/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 34797.8008 - accuracy: 0.8141\n",
      "Epoch 15/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34738.4922 - accuracy: 0.8141\n",
      "Epoch 16/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 34697.0234 - accuracy: 0.8141s - loss: 3\n",
      "Epoch 17/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34666.8242 - accuracy: 0.8141\n",
      "Epoch 18/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34627.7930 - accuracy: 0.8141\n",
      "Epoch 19/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34607.6719 - accuracy: 0.8141\n",
      "Epoch 20/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34542.2109 - accuracy: 0.8141\n",
      "Epoch 21/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34490.3008 - accuracy: 0.8141\n",
      "Epoch 22/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 34407.6016 - accuracy: 0.8141\n",
      "Epoch 23/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34356.6094 - accuracy: 0.8141\n",
      "Epoch 24/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34293.7812 - accuracy: 0.8140s - loss: 34175.3\n",
      "Epoch 25/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34227.4570 - accuracy: 0.8140\n",
      "Epoch 26/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 34161.2617 - accuracy: 0.8138\n",
      "Epoch 27/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 34014.1055 - accuracy: 0.8136\n",
      "Epoch 28/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 33871.1836 - accuracy: 0.8135\n",
      "Epoch 29/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 33713.5664 - accuracy: 0.8134\n",
      "Epoch 30/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 33575.9570 - accuracy: 0.8131\n",
      "Epoch 31/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 33410.0195 - accuracy: 0.8127\n",
      "Epoch 32/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 33205.6094 - accuracy: 0.8121\n",
      "Epoch 33/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 32922.6641 - accuracy: 0.8106\n",
      "Epoch 34/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 32578.1387 - accuracy: 0.8093\n",
      "Epoch 35/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 32195.1074 - accuracy: 0.8083\n",
      "Epoch 36/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 31785.2500 - accuracy: 0.8072\n",
      "Epoch 37/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 31348.5273 - accuracy: 0.8057\n",
      "Epoch 38/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 30879.2559 - accuracy: 0.8023\n",
      "Epoch 39/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 30377.6797 - accuracy: 0.7987\n",
      "Epoch 40/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 29800.0078 - accuracy: 0.7978\n",
      "Epoch 41/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 29262.1484 - accuracy: 0.7976\n",
      "Epoch 42/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 28858.7227 - accuracy: 0.7976\n",
      "Epoch 43/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 28634.0586 - accuracy: 0.7978\n",
      "Epoch 44/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 28377.7676 - accuracy: 0.7981\n",
      "Epoch 45/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 28204.5488 - accuracy: 0.7981\n",
      "Epoch 46/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 28067.1484 - accuracy: 0.7980s - loss: 28232.7852 - ac\n",
      "Epoch 47/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27948.8203 - accuracy: 0.7978\n",
      "Epoch 48/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27780.5332 - accuracy: 0.7980\n",
      "Epoch 49/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27736.0391 - accuracy: 0.7980\n",
      "Epoch 50/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27594.5078 - accuracy: 0.7980\n",
      "Epoch 51/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 27542.3008 - accuracy: 0.7980\n",
      "Epoch 52/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27474.1562 - accuracy: 0.7978\n",
      "Epoch 53/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27364.8984 - accuracy: 0.7980\n",
      "Epoch 54/100\n",
      "90/90 [==============================] - 10s 110ms/step - loss: 27287.6406 - accuracy: 0.7979\n",
      "Epoch 55/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 27252.0332 - accuracy: 0.7978\n",
      "Epoch 56/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27071.4395 - accuracy: 0.7977\n",
      "Epoch 57/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 27040.0137 - accuracy: 0.7977\n",
      "Epoch 58/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 26726.9961 - accuracy: 0.7975\n",
      "Epoch 59/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 26628.8789 - accuracy: 0.7973\n",
      "Epoch 60/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 26438.9629 - accuracy: 0.7974\n",
      "Epoch 61/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 26337.0156 - accuracy: 0.7974\n",
      "Epoch 62/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 26240.2402 - accuracy: 0.7973\n",
      "Epoch 63/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 26134.5293 - accuracy: 0.7976\n",
      "Epoch 64/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 26167.9238 - accuracy: 0.7974\n",
      "Epoch 65/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 26055.7148 - accuracy: 0.7977\n",
      "Epoch 66/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 26037.7324 - accuracy: 0.7977\n",
      "Epoch 67/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25977.7070 - accuracy: 0.7977\n",
      "Epoch 68/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 26000.6270 - accuracy: 0.7978\n",
      "Epoch 69/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25984.9512 - accuracy: 0.7978\n",
      "Epoch 70/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 25946.5723 - accuracy: 0.7976\n",
      "Epoch 71/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 25901.5566 - accuracy: 0.7980\n",
      "Epoch 72/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 25836.2402 - accuracy: 0.7981\n",
      "Epoch 73/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 25808.6270 - accuracy: 0.7981\n",
      "Epoch 74/100\n",
      "90/90 [==============================] - 10s 108ms/step - loss: 25819.2227 - accuracy: 0.7981\n",
      "Epoch 75/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 25848.6797 - accuracy: 0.7984\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 10s 107ms/step - loss: 25782.6641 - accuracy: 0.7984s - loss: 25834\n",
      "Epoch 77/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25770.3652 - accuracy: 0.7985\n",
      "Epoch 78/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25792.7578 - accuracy: 0.7985\n",
      "Epoch 79/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25731.7129 - accuracy: 0.7984\n",
      "Epoch 80/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25786.8555 - accuracy: 0.7988\n",
      "Epoch 81/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25766.4883 - accuracy: 0.7988\n",
      "Epoch 82/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25691.6680 - accuracy: 0.7990\n",
      "Epoch 83/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25679.7969 - accuracy: 0.7990\n",
      "Epoch 84/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25682.1367 - accuracy: 0.7990\n",
      "Epoch 85/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25641.5137 - accuracy: 0.7991\n",
      "Epoch 86/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25653.8320 - accuracy: 0.7991\n",
      "Epoch 87/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25628.5215 - accuracy: 0.7992\n",
      "Epoch 88/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 25689.2715 - accuracy: 0.7994\n",
      "Epoch 89/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25678.4570 - accuracy: 0.7994\n",
      "Epoch 90/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25608.2012 - accuracy: 0.7997\n",
      "Epoch 91/100\n",
      "90/90 [==============================] - 9s 106ms/step - loss: 25568.3926 - accuracy: 0.7997\n",
      "Epoch 92/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25617.1836 - accuracy: 0.7997\n",
      "Epoch 93/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25568.0449 - accuracy: 0.7995\n",
      "Epoch 94/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25549.9590 - accuracy: 0.7997\n",
      "Epoch 95/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25544.8730 - accuracy: 0.7997\n",
      "Epoch 96/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25574.3457 - accuracy: 0.7997\n",
      "Epoch 97/100\n",
      "90/90 [==============================] - 9s 106ms/step - loss: 25562.1035 - accuracy: 0.79970s - loss: 25852.363\n",
      "Epoch 98/100\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 25532.7422 - accuracy: 0.7999\n",
      "Epoch 99/100\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 25495.0215 - accuracy: 0.7999\n",
      "Epoch 100/100\n",
      "90/90 [==============================] - 10s 109ms/step - loss: 25493.0742 - accuracy: 0.7999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = autoencoder.fit(X_train_scaled, X_train_scaled,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                verbose=1)\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 25541.59590293752 \n",
      "MSE test  : 26834.885744139337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def print_mse(compute_pred = lambda x :autoencoder.predict(x)):\n",
    "    ae_of_train = mean_squared_error(X_train_scaled.reshape(-1),compute_pred(X_train_scaled).reshape(-1))\n",
    "    ae_of_test = mean_squared_error(X_test_scaled.reshape(-1), compute_pred(X_test_scaled).reshape(-1))\n",
    "    print(f\"MSE train : {ae_of_train} \\nMSE test  : {ae_of_test}\")\n",
    "print_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 1237.185732071038 \n",
      "MSE test  : 1838.7659055421211\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=100)\n",
    "tX_train = X_train_scaled.reshape(N_train,-1)\n",
    "tX_test = X_test_scaled.reshape(N - N_train,-1)\n",
    "pca.fit(tX_train)\n",
    "#print_mse(lambda x: pca.inverse_transform(pca.transform(tX_train)))\n",
    "pca_train = mean_squared_error(tX_train, pca.inverse_transform(pca.transform(tX_train)))\n",
    "pca_test =  mean_squared_error(tX_test, pca.inverse_transform(pca.transform(tX_test)))\n",
    "print(f\"MSE train : {pca_train} \\nMSE test  : {pca_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:20:06.729392: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('autoencoder_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model('autoencoder_model')\n",
    "X = np.load(cfg['files'][\"raw_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ -5.32015037,  17.99999898],\n",
       "         [ -4.45695528,  16.99999949],\n",
       "         [ -4.49284688,  16.99999949],\n",
       "         ...,\n",
       "         [ -1.6863906 ,  41.00999987],\n",
       "         [ -1.66454188,  41.00999987],\n",
       "         [ -1.6680385 ,  32.99999949]],\n",
       "\n",
       "        [[  7.29062134,  25.99999898],\n",
       "         [  9.47089524,  30.00000102],\n",
       "         [  9.10894194,  28.99999949],\n",
       "         ...,\n",
       "         [  0.        ,   0.        ],\n",
       "         [  0.        ,   0.        ],\n",
       "         [  0.        ,   0.        ]],\n",
       "\n",
       "        [[-11.6484556 ,  44.23192576],\n",
       "         [-11.07534862,  35.00000051],\n",
       "         [-11.04633346, 101.00000358],\n",
       "         ...,\n",
       "         [-10.09539986,  20.99999949],\n",
       "         [-10.08533068,  18.7499991 ],\n",
       "         [-10.12098522,  28.        ]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 600, 2), dtype=float32, numpy=\n",
       "array([[[[ 0.       , 11.931336 ],\n",
       "         [ 0.       , 11.46713  ],\n",
       "         [ 0.       , 11.851921 ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       , 30.082447 ],\n",
       "         [ 0.       , 47.8061   ],\n",
       "         [ 0.       , 29.722042 ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ]],\n",
       "\n",
       "        [[ 0.       ,  1.2651794],\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  3.905907 ],\n",
       "         ...,\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ],\n",
       "         [ 0.       ,  0.       ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder(X[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 600, 2), dtype=float32, numpy=\n",
       "array([[[[  0.      ,  33.47847 ],\n",
       "         [  0.      ,  34.10285 ],\n",
       "         [  0.      ,  34.3735  ],\n",
       "         ...,\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ]],\n",
       "\n",
       "        [[  0.      ,  92.61729 ],\n",
       "         [  0.      , 152.37823 ],\n",
       "         [  0.      , 103.295334],\n",
       "         ...,\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ]],\n",
       "\n",
       "        [[  0.      ,  10.691814],\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,  27.942345],\n",
       "         ...,\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ],\n",
       "         [  0.      ,   0.      ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder(X[100:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_layer = 5\n",
    "\n",
    "def extract_layers(main_model, starting_layer_ix, ending_layer_ix):\n",
    "    \"\"\"extract layers between starting_layer_ix and ending_layer_ix from a given model\"\"\"\n",
    "     # create an empty model\n",
    "    new_model = keras.Sequential()\n",
    "    for ix in range(starting_layer_ix, ending_layer_ix + 1):\n",
    "        curr_layer = main_model.get_layer(index=ix)\n",
    "    # copy this layer over to the new model\n",
    "        new_model.add(curr_layer)\n",
    "    return new_model\n",
    "# extract en encoder part of the autoencoder\n",
    "encoder = extract_layers(autoencoder,0,encoding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.load(cfg['files']['raw_train_features'])\n",
    "np.isnan(X_train).any()\n",
    "#encoder(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id  =np.load(cfg['files']['train_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3144, 9939, 7925, ..., 5218, 1346, 3582])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3144].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(X_train.shape[0]):\n",
    "    a.append(X_train[i].max())\n",
    "a = np.array(a)\n",
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[a == 0])/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(X.shape[0]):\n",
    "    a.append(X[i].max())\n",
    "a = np.array(a)\n",
    "a.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[11.74618272, 14.        ],\n",
       "        [11.72472664, 30.00000102],\n",
       "        [11.68929914, 46.00000102],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[-6.44173954, 30.00000102],\n",
       "        [-6.38766396, 30.00000102],\n",
       "        [-6.29579457, 28.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]],\n",
       "\n",
       "       [[-5.29522908, 12.99999949],\n",
       "        [-5.29489376, 33.99999898],\n",
       "        [-5.29439048, 35.99999795],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[672]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c80cda4c1eab7d6fd1dc9dde18fc294f1832305a125f1fb8ec87a584595fc9f7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
