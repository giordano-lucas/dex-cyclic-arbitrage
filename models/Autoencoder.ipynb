{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 11:51:58.242829: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/scratch/izar/kapps/DEX-Cyclic-Arbitrage/\")\n",
    "from config.get import cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(cfg['files'][\"raw_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train/test split and standard scaling \n",
    "test_size = 0.3\n",
    "N =  X.shape[0]\n",
    "N_train = int(N * (1 - test_size))\n",
    "X_train, X_test, train_id, test_id = train_test_split(X, np.arange(X.shape[0]),test_size=test_size, random_state=123)\n",
    "\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "\n",
    "#X_train_scaled = scaler.transform(X_train)\n",
    "#X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/scratch/izar/kapps/DEX-Cyclic-Arbitrage/data/ML_features/raw_test_features.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15892/3472032070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_test_features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_train_features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_test_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'files'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_train_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtrain_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/ssoft/spack/arvine/v1/opt/spack/linux-rhel7-skylake_avx512/gcc-8.4.0/python-3.7.7-drpdlwdbo3lmtkcbckq227ypnzno4ek3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/scratch/izar/kapps/DEX-Cyclic-Arbitrage/data/ML_features/raw_test_features.npy'"
     ]
    }
   ],
   "source": [
    "np.save(cfg['files']['raw_test_features'] , X_test)\n",
    "np.save(cfg['files']['raw_train_features'] ,X_train)\n",
    "np.save(cfg['files']['raw_test_ids'] , test_id)\n",
    "np.save(cfg['files']['raw_train_ids'] , train_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(params):\n",
    "    # build encoder\n",
    "    input_img = keras.Input(shape=(3,600, 2))\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((3, 3), padding='same')(x)\n",
    "    x = layers.Conv2D(4, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    encoded = layers.Conv2D(1, (2, 2), activation='relu', padding='same')(x)\n",
    "    # build decoder\n",
    "    x = layers.Conv2D(4, (2, 2), activation='relu', padding='same')(encoded)\n",
    "    x = layers.UpSampling2D((1, 2))(x)\n",
    "    x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((3, 3))(x)\n",
    "    decoded = layers.Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
    "    # combine encoder and decoder\n",
    "    autoencoder = keras.Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', metrics=['accuracy'], loss='mean_squared_error',)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3, 600, 2)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 600, 8)         152       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 200, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 200, 4)         292       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 100, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 100, 1)         17        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 100, 4)         20        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 1, 200, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 200, 8)         296       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 3, 600, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 600, 2)         146       \n",
      "=================================================================\n",
      "Total params: 923\n",
      "Trainable params: 923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = build_model()\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "292/292 [==============================] - 33s 111ms/step - loss: 48121.2930 - accuracy: 0.7959\n",
      "Epoch 2/500\n",
      "292/292 [==============================] - 31s 108ms/step - loss: 41257.3086 - accuracy: 0.8351\n",
      "Epoch 3/500\n",
      "145/292 [=============>................] - ETA: 18s - loss: 39921.9102 - accuracy: 0.8333"
     ]
    }
   ],
   "source": [
    "# fit function for talos\n",
    "def fit_model(X_train, y_train, X_val, y_val, params):\n",
    "    # build model\n",
    "    autoencoder = build_model(params)\n",
    "    # fit model\n",
    "    out = autoencoder.fit(\n",
    "        X_train_scaled, X_train_scaled,\n",
    "        epochs=500,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        batch_size=params['batch_size'],\n",
    "        epochs=params['epochs'],\n",
    "        validation_data=[x_val, y_val],\n",
    "        verbose=0,\n",
    "        callbacks=[talos.utils.early_stopper(params['epochs'])],\n",
    "    )\n",
    "    plt.plot(out.history[\"loss\"])\n",
    "    plt.show()\n",
    "    return out, autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.activations import relu, elu\n",
    "## the parameter that you want to be optimized are defined in this dictionnary\n",
    "p = {'activation':['relu', 'elu'],\n",
    "     'losses': ['logcosh'],\n",
    "     'shapes': ['brick'],\n",
    "     'first_neuron': [32],\n",
    "     'dropout': [.2, .3],\n",
    "     'batch_size': [32, 64],\n",
    "     'epochs': [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_object = talos.Scan(\n",
    "    x=X_train, y=y_train, params=p, \n",
    "    model=fit_model, \n",
    "    experiment_name='ml4f-autoencoder', \n",
    "    x_val=X_val, y_val=y_val\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_object.evaluate_models(\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    n_models=10,\n",
    "    metric='f1score',\n",
    "    folds=5,\n",
    "    shuffle=True,\n",
    "    average='binary',\n",
    "    asc=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_object.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 25541.59590293752 \n",
      "MSE test  : 26834.885744139337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def print_mse(compute_pred = lambda x :autoencoder.predict(x)):\n",
    "    ae_of_train = mean_squared_error(X_train_scaled.reshape(-1),compute_pred(X_train_scaled).reshape(-1))\n",
    "    ae_of_test = mean_squared_error(X_test_scaled.reshape(-1), compute_pred(X_test_scaled).reshape(-1))\n",
    "    print(f\"MSE train : {ae_of_train} \\nMSE test  : {ae_of_test}\")\n",
    "print_mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train : 1237.185732071038 \n",
      "MSE test  : 1838.7659055421211\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=100)\n",
    "tX_train = X_train_scaled.reshape(N_train,-1)\n",
    "tX_test = X_test_scaled.reshape(N - N_train,-1)\n",
    "pca.fit(tX_train)\n",
    "#print_mse(lambda x: pca.inverse_transform(pca.transform(tX_train)))\n",
    "pca_train = mean_squared_error(tX_train, pca.inverse_transform(pca.transform(tX_train)))\n",
    "pca_test =  mean_squared_error(tX_test, pca.inverse_transform(pca.transform(tX_test)))\n",
    "print(f\"MSE train : {pca_train} \\nMSE test  : {pca_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 15:20:06.729392: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('autoencoder_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model('autoencoder_model')\n",
    "X = np.load(cfg['files'][\"raw_features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_layer = 5\n",
    "\n",
    "def extract_layers(main_model, starting_layer_ix, ending_layer_ix):\n",
    "    \"\"\"extract layers between starting_layer_ix and ending_layer_ix from a given model\"\"\"\n",
    "     # create an empty model\n",
    "    new_model = keras.Sequential()\n",
    "    for ix in range(starting_layer_ix, ending_layer_ix + 1):\n",
    "        curr_layer = main_model.get_layer(index=ix)\n",
    "    # copy this layer over to the new model\n",
    "        new_model.add(curr_layer)\n",
    "    return new_model\n",
    "# extract en encoder part of the autoencoder\n",
    "encoder = extract_layers(autoencoder,0,encoding_layer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c80cda4c1eab7d6fd1dc9dde18fc294f1832305a125f1fb8ec87a584595fc9f7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
