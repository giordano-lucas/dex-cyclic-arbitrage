{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b03ba1f",
   "metadata": {},
   "source": [
    "# Models training \n",
    "This notebook is used to train test and save models that are defined in the `autoencoders.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "316e97b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('ggplot')\n",
    "import sys \n",
    "import os\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:4]))\n",
    "from config.get import cfg\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240338a1",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d57fb1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : X_train=(5292, 3, 600, 2),X_test=(1323, 3, 600, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(cfg['files'][\"liquid\"][\"raw_train_features\"])\n",
    "X_test  = np.load(cfg['files'][\"liquid\"][\"raw_test_features\"])\n",
    "print(f\"shapes : X_train={X_train.shape},X_test={X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48d7f9",
   "metadata": {},
   "source": [
    "# Loading model\n",
    "Loading a model defined in `autoencoders.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b09a76d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 3, 600, 2)]       0         \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 3600)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 600)               2160600   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               60100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 600)               60600     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3600)              2163600   \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 3, 600, 2)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,444,900\n",
      "Trainable params: 4,444,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name,autoencoder = autoencoders.fully_connected_3L()\n",
    "autoencoder.summary()\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6dd38b",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e9cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "166/166 [==============================] - 20s 116ms/step - loss: 0.2414 - val_loss: 0.1465\n",
      "Epoch 2/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.1333 - val_loss: 0.1170\n",
      "Epoch 3/70\n",
      "166/166 [==============================] - 19s 117ms/step - loss: 0.1136 - val_loss: 0.1098\n",
      "Epoch 4/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.1072 - val_loss: 0.1008\n",
      "Epoch 5/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0975 - val_loss: 0.1014\n",
      "Epoch 6/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0984 - val_loss: 0.0933\n",
      "Epoch 7/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.1021 - val_loss: 0.0922\n",
      "Epoch 8/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0894 - val_loss: 0.0874\n",
      "Epoch 9/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0842 - val_loss: 0.0863\n",
      "Epoch 10/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0832 - val_loss: 0.0832\n",
      "Epoch 11/70\n",
      "166/166 [==============================] - 19s 115ms/step - loss: 0.0824 - val_loss: 0.0810\n",
      "Epoch 12/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0761 - val_loss: 0.0826\n",
      "Epoch 13/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0799 - val_loss: 0.0817\n",
      "Epoch 14/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0830 - val_loss: 0.0906\n",
      "Epoch 15/70\n",
      "166/166 [==============================] - 19s 113ms/step - loss: 0.0793 - val_loss: 0.0788\n",
      "Epoch 16/70\n",
      "166/166 [==============================] - 19s 115ms/step - loss: 0.0748 - val_loss: 0.0787\n",
      "Epoch 17/70\n",
      "166/166 [==============================] - 19s 115ms/step - loss: 0.0873 - val_loss: 0.0981\n",
      "Epoch 18/70\n",
      "166/166 [==============================] - 19s 114ms/step - loss: 0.0795 - val_loss: 0.0816\n",
      "Epoch 19/70\n",
      "166/166 [==============================] - 19s 116ms/step - loss: 0.0885 - val_loss: 0.0761\n",
      "Epoch 20/70\n",
      "166/166 [==============================] - 19s 112ms/step - loss: 0.0708 - val_loss: 0.0736\n",
      "Epoch 21/70\n",
      "166/166 [==============================] - 18s 107ms/step - loss: 0.0697 - val_loss: 0.0725\n",
      "Epoch 22/70\n",
      "166/166 [==============================] - 18s 107ms/step - loss: 0.0684 - val_loss: 0.0749\n",
      "Epoch 23/70\n",
      "166/166 [==============================] - 19s 112ms/step - loss: 0.0697 - val_loss: 0.0733\n",
      "Epoch 24/70\n",
      "166/166 [==============================] - 19s 113ms/step - loss: 0.0677 - val_loss: 0.0718\n",
      "Epoch 25/70\n",
      "166/166 [==============================] - 18s 110ms/step - loss: 0.0761 - val_loss: 0.0761\n",
      "Epoch 26/70\n",
      "166/166 [==============================] - 17s 105ms/step - loss: 0.0693 - val_loss: 0.0717\n",
      "Epoch 27/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0673 - val_loss: 0.0716\n",
      "Epoch 28/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0667 - val_loss: 0.0833\n",
      "Epoch 29/70\n",
      "166/166 [==============================] - 16s 98ms/step - loss: 0.0680 - val_loss: 0.0724\n",
      "Epoch 30/70\n",
      "166/166 [==============================] - 17s 100ms/step - loss: 0.0645 - val_loss: 0.0712\n",
      "Epoch 31/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0631 - val_loss: 0.0718\n",
      "Epoch 32/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0707 - val_loss: 0.0922\n",
      "Epoch 33/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0749 - val_loss: 0.0702\n",
      "Epoch 34/70\n",
      "166/166 [==============================] - 16s 99ms/step - loss: 0.0634 - val_loss: 0.0724\n",
      "Epoch 35/70\n",
      "166/166 [==============================] - 17s 100ms/step - loss: 0.0641 - val_loss: 0.0709\n",
      "Epoch 36/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0636 - val_loss: 0.0691\n",
      "Epoch 37/70\n",
      "166/166 [==============================] - 17s 99ms/step - loss: 0.0657 - val_loss: 0.0685\n",
      "Epoch 38/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0642 - val_loss: 0.0721\n",
      "Epoch 39/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0634 - val_loss: 0.0686\n",
      "Epoch 40/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0622 - val_loss: 0.0683\n",
      "Epoch 41/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0618 - val_loss: 0.0769\n",
      "Epoch 42/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0652 - val_loss: 0.0675\n",
      "Epoch 43/70\n",
      "166/166 [==============================] - 17s 103ms/step - loss: 0.0613 - val_loss: 0.0668\n",
      "Epoch 44/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0654 - val_loss: 0.0694\n",
      "Epoch 45/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0612 - val_loss: 0.0674\n",
      "Epoch 46/70\n",
      "166/166 [==============================] - 17s 103ms/step - loss: 0.0603 - val_loss: 0.0672\n",
      "Epoch 47/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0595 - val_loss: 0.0693\n",
      "Epoch 48/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0610 - val_loss: 0.0679\n",
      "Epoch 49/70\n",
      "166/166 [==============================] - 17s 103ms/step - loss: 0.0596 - val_loss: 0.0736\n",
      "Epoch 50/70\n",
      "166/166 [==============================] - 17s 99ms/step - loss: 0.0879 - val_loss: 0.0711\n",
      "Epoch 51/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0613 - val_loss: 0.0679\n",
      "Epoch 52/70\n",
      "166/166 [==============================] - 17s 104ms/step - loss: 0.0585 - val_loss: 0.0674\n",
      "Epoch 53/70\n",
      "166/166 [==============================] - 17s 101ms/step - loss: 0.0600 - val_loss: 0.0736\n",
      "Epoch 54/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0621 - val_loss: 0.0664\n",
      "Epoch 55/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0576 - val_loss: 0.0664\n",
      "Epoch 56/70\n",
      "166/166 [==============================] - 17s 102ms/step - loss: 0.0574 - val_loss: 0.0667\n",
      "Epoch 57/70\n",
      "111/166 [===================>..........] - ETA: 5s - loss: 0.0596"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.fit(X_train, X_train,epochs=70,validation_data=(X_test, X_test))\n",
    "\n",
    "# save losses\n",
    "train_loss += hist.history[\"loss\"]\n",
    "test_loss  += hist.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed156905",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,label=\"train\")\n",
    "plt.plot(test_loss,label=\"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8bdfef",
   "metadata": {},
   "source": [
    "# Saving \n",
    "We save the trained model and the recorded losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(cfg[\"models\"][\"autoencoder\"] + f\"{model_name}\")\n",
    "np.save(file = cfg[\"models\"][\"autoencoder\"]+ f\"{model_name}_train_loss\", arr = np.array(train_loss))\n",
    "np.save(file = cfg[\"models\"][\"autoencoder\"]+ f\"{model_name}_test_loss\", arr = np.array(test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
