{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b03ba1f",
   "metadata": {},
   "source": [
    "# Models training \n",
    "This notebook is used to train test and save models that are defined in the `autoencoders.py` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316e97b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 17:15:12.754487: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-11 17:15:12.754529: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('ggplot')\n",
    "import sys \n",
    "import os\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:4]))\n",
    "from config.get import cfg\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240338a1",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57fb1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes : X_train=(4963, 3, 600, 2),X_test=(1241, 3, 600, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load(cfg['files'][\"liquid\"][\"scaled_ae_train_features\"])\n",
    "X_test  = np.load(cfg['files'][\"liquid\"][\"raw_test_features\"])\n",
    "print(f\"shapes : X_train={X_train.shape},X_test={X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48d7f9",
   "metadata": {},
   "source": [
    "# Loading model\n",
    "Loading a model defined in `autoencoders.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bec6027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b09a76d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 3, 600, 2)]       0         \n",
      "                                                                 \n",
      " reshape_40 (Reshape)        (None, 3600)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 3600)              12963600  \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 100)               360100    \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 3600)              363600    \n",
      "                                                                 \n",
      " reshape_41 (Reshape)        (None, 3, 600, 2)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,687,300\n",
      "Trainable params: 13,687,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"activation\" : \"selu\",\n",
    "    \"dense_layers\":3,\n",
    "    \"dropout\":0,\n",
    "    \"epochs\":70,\n",
    "    \"first_neuron\":900,\n",
    "    \"optimizer\":\"Adamax\"\n",
    "}\n",
    "\n",
    "\n",
    "def FC():\n",
    "    model_name = \"fully_connected\"\n",
    "    in_shape = (3,600, 2) \n",
    "    # build encoder\n",
    "    input_layer = keras.Input(shape=in_shape)\n",
    "    x = layers.Reshape([in_shape[0]*in_shape[1]*in_shape[2]])(input_layer)\n",
    "    x = layers.Dense(in_shape[0]*in_shape[1]*in_shape[2],  activation='selu')(x)\n",
    "    x = layers.Dense(100,  activation='selu')(x)\n",
    "    x = layers.Dense(in_shape[0]*in_shape[1]*in_shape[2],  activation='selu')(x)\n",
    "    output_layer =layers.Reshape(in_shape)(x)\n",
    "    \n",
    "    \n",
    "    # combine encoder and decoder\n",
    "    autoencoder = keras.Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer='Adamax', loss='mean_squared_error',)\n",
    "    return model_name ,autoencoder\n",
    "\n",
    "model_name,autoencoder = FC()  \n",
    "\n",
    "#model_name,autoencoder = fully_connected_3L()\n",
    "autoencoder.summary()\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6dd38b",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e9cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "311/311 [==============================] - 97s 310ms/step - loss: 0.5321 - val_loss: 0.3777\n",
      "Epoch 2/20\n",
      "311/311 [==============================] - 95s 306ms/step - loss: 0.2602 - val_loss: 0.2893\n",
      "Epoch 3/20\n",
      "311/311 [==============================] - 90s 291ms/step - loss: 0.2066 - val_loss: 0.2569\n",
      "Epoch 4/20\n",
      "311/311 [==============================] - 89s 287ms/step - loss: 0.1838 - val_loss: 0.2389\n",
      "Epoch 5/20\n",
      "311/311 [==============================] - 92s 296ms/step - loss: 0.1671 - val_loss: 0.2235\n",
      "Epoch 6/20\n",
      "311/311 [==============================] - 94s 301ms/step - loss: 0.1549 - val_loss: 0.2145\n",
      "Epoch 7/20\n",
      "311/311 [==============================] - 94s 301ms/step - loss: 0.1460 - val_loss: 0.2107\n",
      "Epoch 8/20\n",
      "311/311 [==============================] - 93s 298ms/step - loss: 0.1402 - val_loss: 0.2025\n",
      "Epoch 9/20\n",
      "311/311 [==============================] - 93s 298ms/step - loss: 0.1349 - val_loss: 0.2009\n",
      "Epoch 10/20\n",
      "311/311 [==============================] - 92s 297ms/step - loss: 0.1312 - val_loss: 0.1941\n",
      "Epoch 11/20\n",
      "311/311 [==============================] - 94s 302ms/step - loss: 0.1290 - val_loss: 0.1932\n",
      "Epoch 12/20\n",
      "311/311 [==============================] - 94s 301ms/step - loss: 0.1263 - val_loss: 0.1880\n",
      "Epoch 13/20\n",
      "311/311 [==============================] - 97s 311ms/step - loss: 0.1243 - val_loss: 0.1893\n",
      "Epoch 14/20\n",
      "311/311 [==============================] - 117s 376ms/step - loss: 0.1224 - val_loss: 0.1887\n",
      "Epoch 15/20\n",
      "311/311 [==============================] - 165s 531ms/step - loss: 0.1214 - val_loss: 0.1857\n",
      "Epoch 16/20\n",
      "311/311 [==============================] - 165s 530ms/step - loss: 0.1207 - val_loss: 0.1846\n",
      "Epoch 17/20\n",
      " 62/311 [====>.........................] - ETA: 2:15 - loss: 0.1177"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.fit(X_train, X_train,epochs=20,validation_data=(X_test, X_test),batch_size=16)\n",
    "\n",
    "# save losses\n",
    "train_loss += hist.history[\"loss\"]\n",
    "test_loss  += hist.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed156905",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,label=\"train\")\n",
    "plt.plot(test_loss,label=\"test\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8bdfef",
   "metadata": {},
   "source": [
    "# Saving \n",
    "We save the trained model and the recorded losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63e8ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(cfg[\"models\"][\"autoencoder\"] + f\"{model_name}\")\n",
    "np.save(file = cfg[\"models\"][\"autoencoder\"]+ f\"{model_name}_train_loss\", arr = np.array(train_loss))\n",
    "np.save(file = cfg[\"models\"][\"autoencoder\"]+ f\"{model_name}_test_loss\", arr = np.array(test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
