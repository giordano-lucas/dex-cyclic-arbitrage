{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907f511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "import tensorflow as tf\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "import sys \n",
    "import os\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:4]))\n",
    "from config.get import cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365a4be",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "Predictions will use embeddings produced by the previously selected embeddings model as features. The target variable of the prediction is the boolean value corresponding to the profitability of cycles. The embedding was shuffled when splitting the embedding model training data. Thus, one needs to rematch each embedding with the corresponding target using `cycle_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c32c2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features\n",
    "X_train = np.load(cfg['files'][\"liquid\"]['encoded_train_features'])\n",
    "X_test  = np.load(cfg['files'][\"liquid\"]['encoded_test_features'])\n",
    "\n",
    "fX_train = pd.read_csv(cfg['files'][\"liquid\"]['additional_features_train'])\n",
    "fX_test  = pd.read_csv(cfg['files'][\"liquid\"]['additional_features_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5e39476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = fX_train.profitability\n",
    "y_test  = fX_test.profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c7af913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453892668178382\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean()) # imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4830d3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9538926681783825\n"
     ]
    }
   ],
   "source": [
    "print(y_test.mean()) # imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eba0f1",
   "metadata": {},
   "source": [
    "# Rescale the features\n",
    "* Embeddings are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62413dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "tX_train = scaler.transform(X_train)\n",
    "tX_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d323c",
   "metadata": {},
   "source": [
    "# Transform train / test into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "47521464",
   "metadata": {},
   "outputs": [],
   "source": [
    "pX_train = pd.DataFrame(data=tX_train, columns=[str(c) for c in range(X_train.shape[1])])\n",
    "pX_test  = pd.DataFrame(data=tX_test,  columns=[str(c) for c in range(X_train.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b663c8",
   "metadata": {},
   "source": [
    "# Token one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5b0f4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class TokenEncoding:\n",
    "    def __init__(self):\n",
    "        self.one_enc = OneHotEncoder(sparse=False, handle_unknown = 'ignore') \n",
    "        self.token_columns = ['token1','token2', 'token3']\n",
    "\n",
    "    def fit_tokens(self,data):\n",
    "        unique_tokens = np.unique(pd.concat([data[token] for token in self.token_columns],axis=0))\n",
    "        self.one_enc.fit(unique_tokens.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform_tokens(self,data):\n",
    "        # transform\n",
    "        encode = lambda col: self.one_enc.transform(data[col].to_numpy().reshape(-1, 1))\n",
    "        # encode and convert as dataframes\n",
    "        encoded = [pd.DataFrame(encode(token)).add_prefix(f\"token_{key}_\") for key,token in enumerate(self.token_columns)]\n",
    "        return pd.concat(encoded, axis='columns').astype('float32')\n",
    "    \n",
    "\n",
    "    def join_tokens(self,data, tokens):\n",
    "        if ('token1' in data.columns):\n",
    "            data = data.drop(columns=self.token_columns)\n",
    "        return pd.concat([data,tokens], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1463f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenEnc = TokenEncoding()\n",
    "tokenEnc.fit_tokens(fX_train)\n",
    "fpX_train = tokenEnc.join_tokens(pX_train, tokenEnc.transform_tokens(fX_train))\n",
    "fpX_test  = tokenEnc.join_tokens(pX_test, tokenEnc.transform_tokens(fX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b8d255c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>token_2_158</th>\n",
       "      <th>token_2_159</th>\n",
       "      <th>token_2_160</th>\n",
       "      <th>token_2_161</th>\n",
       "      <th>token_2_162</th>\n",
       "      <th>token_2_163</th>\n",
       "      <th>token_2_164</th>\n",
       "      <th>token_2_165</th>\n",
       "      <th>token_2_166</th>\n",
       "      <th>token_2_167</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.505291</td>\n",
       "      <td>0.579465</td>\n",
       "      <td>-0.637919</td>\n",
       "      <td>1.917729</td>\n",
       "      <td>-0.471626</td>\n",
       "      <td>-0.269707</td>\n",
       "      <td>-0.487739</td>\n",
       "      <td>0.380295</td>\n",
       "      <td>-0.388063</td>\n",
       "      <td>-0.292947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.862282</td>\n",
       "      <td>0.464563</td>\n",
       "      <td>-0.633860</td>\n",
       "      <td>2.143126</td>\n",
       "      <td>-0.487417</td>\n",
       "      <td>-0.310520</td>\n",
       "      <td>-0.494301</td>\n",
       "      <td>1.236678</td>\n",
       "      <td>-0.266514</td>\n",
       "      <td>-0.230577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573433</td>\n",
       "      <td>-0.535478</td>\n",
       "      <td>-0.576774</td>\n",
       "      <td>-0.489549</td>\n",
       "      <td>-0.454229</td>\n",
       "      <td>2.182124</td>\n",
       "      <td>0.244653</td>\n",
       "      <td>-0.415567</td>\n",
       "      <td>-0.304272</td>\n",
       "      <td>0.855866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643999</td>\n",
       "      <td>-0.542200</td>\n",
       "      <td>-0.564201</td>\n",
       "      <td>-0.490966</td>\n",
       "      <td>-0.448616</td>\n",
       "      <td>2.199132</td>\n",
       "      <td>0.246344</td>\n",
       "      <td>-0.418407</td>\n",
       "      <td>-0.323347</td>\n",
       "      <td>0.821669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.517683</td>\n",
       "      <td>-0.483488</td>\n",
       "      <td>-0.372736</td>\n",
       "      <td>-0.488034</td>\n",
       "      <td>-0.442421</td>\n",
       "      <td>-0.195371</td>\n",
       "      <td>-0.407583</td>\n",
       "      <td>-0.498525</td>\n",
       "      <td>-0.312150</td>\n",
       "      <td>-0.622698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.505291  0.579465 -0.637919  1.917729 -0.471626 -0.269707 -0.487739   \n",
       "1  0.862282  0.464563 -0.633860  2.143126 -0.487417 -0.310520 -0.494301   \n",
       "2  0.573433 -0.535478 -0.576774 -0.489549 -0.454229  2.182124  0.244653   \n",
       "3  0.643999 -0.542200 -0.564201 -0.490966 -0.448616  2.199132  0.246344   \n",
       "4 -0.517683 -0.483488 -0.372736 -0.488034 -0.442421 -0.195371 -0.407583   \n",
       "\n",
       "          7         8         9  ...  token_2_158  token_2_159  token_2_160  \\\n",
       "0  0.380295 -0.388063 -0.292947  ...          0.0          0.0          0.0   \n",
       "1  1.236678 -0.266514 -0.230577  ...          0.0          0.0          0.0   \n",
       "2 -0.415567 -0.304272  0.855866  ...          0.0          0.0          0.0   \n",
       "3 -0.418407 -0.323347  0.821669  ...          0.0          0.0          0.0   \n",
       "4 -0.498525 -0.312150 -0.622698  ...          0.0          0.0          0.0   \n",
       "\n",
       "   token_2_161  token_2_162  token_2_163  token_2_164  token_2_165  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   token_2_166  token_2_167  \n",
       "0          0.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          0.0          0.0  \n",
       "3          0.0          0.0  \n",
       "4          0.0          0.0  \n",
       "\n",
       "[5 rows x 604 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpX_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2addb79",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e45db8",
   "metadata": {},
   "source": [
    "## model creation & fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cd8ef2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(X_train, y_train):\n",
    "    logistic_model = LogisticRegressionCV(\n",
    "        cv=5,\n",
    "        Cs=np.logspace(-4,4,10),\n",
    "        max_iter=5000,\n",
    "        class_weight=\"balanced\")\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    return logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1415fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = fit_logistic(tX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf78ca",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ae8400ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion(tn, fp, fn, tp):\n",
    "    print(f\"True neg : {tn} | False pos : {fp} | False neg : {fn} | True pos : {tp}\")\n",
    "    print(tabulate([['True (real)',tp, fn], ['False (Real)',fp, tn]], headers=['\\\\', 'True (pred)' ,\" False (pred)\"], tablefmt='fancy_grid'))\n",
    "   \n",
    "def evaluate_model(model,test_set=tX_test):\n",
    "\n",
    "    pred = model.predict(test_set)>0.5\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,pred).ravel()\n",
    "    print_confusion(tn, fp, fn, tp)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print(f\"f1 score={f1:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8ca64a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True neg : 24 | False pos : 37 | False neg : 472 | True pos : 790\n",
      "╒══════════════╤═══════════════╤═════════════════╕\n",
      "│ \\            │   True (pred) │    False (pred) │\n",
      "╞══════════════╪═══════════════╪═════════════════╡\n",
      "│ True (real)  │           790 │             472 │\n",
      "├──────────────┼───────────────┼─────────────────┤\n",
      "│ False (Real) │            37 │              24 │\n",
      "╘══════════════╧═══════════════╧═════════════════╛\n",
      "f1 score=0.7563\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(logistic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1540e",
   "metadata": {},
   "source": [
    "## Let's add the token encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7362050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True neg : 17 | False pos : 44 | False neg : 378 | True pos : 884\n",
      "╒══════════════╤═══════════════╤═════════════════╕\n",
      "│ \\            │   True (pred) │    False (pred) │\n",
      "╞══════════════╪═══════════════╪═════════════════╡\n",
      "│ True (real)  │           884 │             378 │\n",
      "├──────────────┼───────────────┼─────────────────┤\n",
      "│ False (Real) │            44 │              17 │\n",
      "╘══════════════╧═══════════════╧═════════════════╛\n",
      "f1 score=0.8073\n"
     ]
    }
   ],
   "source": [
    "logistic_model = fit_logistic(fpX_train, y_train)\n",
    "evaluate_model(logistic_model, test_set=fpX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614c3af",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55523cd8",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b273e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_parameters = {'kernel':('linear', 'rbf','poly'), 'C':np.logspace(-4,4,5)}\n",
    "svc = svm.SVC()\n",
    "svm_model = GridSearchCV(svc, svm_parameters,verbose=1,cv = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee1706",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ca5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(tX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e8fa",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a17362",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(svm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5e9e5",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8575372",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "This new prediction method works on the raw data (not embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a6ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9333, 3600) (4001, 3600)\n"
     ]
    }
   ],
   "source": [
    "# load the features\n",
    "X_train_NN = np.load(cfg['files']['raw_train_features'])\n",
    "X_test_NN  = np.load(cfg['files']['raw_test_features'])\n",
    "\n",
    "\n",
    "X_train_NN = X_train_NN.reshape((len(X_train_NN),-1))\n",
    "X_test_NN = X_test_NN.reshape((len(X_test_NN),-1))\n",
    "print(X_train_NN.shape,X_test_NN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04035f",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09af30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_scaler = StandardScaler()\n",
    "NN_scaler.fit(X_train_NN)\n",
    "tX_train_NN = NN_scaler.transform(X_train_NN)\n",
    "tX_test_NN  = NN_scaler.transform(X_test_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50c23a",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234d2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = X_train_NN.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580c432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-30 13:36:40.054474: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-12-30 13:36:40.054528: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (izar): /proc/driver/nvidia/version does not exist\n",
      "2021-12-30 13:36:40.055970: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "NN_model = tf.keras.Sequential()\n",
    "NN_model.add(tf.keras.Input(shape=d))\n",
    "NN_model.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
    "NN_model.add(tf.keras.layers.Dense(50,activation=\"relu\"))\n",
    "NN_model.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14585ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               360100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 365,201\n",
      "Trainable params: 365,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f6fa7",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7174ff2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "compute_class_weight() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33897/2199289988.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m class_weights = class_weight.compute_class_weight('balanced',\n\u001b[1;32m      4\u001b[0m                                                  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                                  y_train)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: compute_class_weight() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38428000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "292/292 [==============================] - 3s 9ms/step - loss: 9267022648477483008.0000A: 3\n",
      "Epoch 2/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2147\n",
      "Epoch 3/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145A: 1s - \n",
      "Epoch 4/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n",
      "Epoch 5/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n",
      "Epoch 6/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n",
      "Epoch 7/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n",
      "Epoch 8/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n",
      "Epoch 9/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n",
      "Epoch 10/10\n",
      "292/292 [==============================] - 2s 8ms/step - loss: 0.2145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b8c27edd850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.compile(optimizer='sgd', loss='binary_crossentropy')\n",
    "# This builds the model for the first time:\n",
    "NN_model.fit(X_train_NN, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1887fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True neg : 0 | False pos : 216 | False neg : 0 | True pos : 3785\n",
      "╒══════════════╤═══════════════╤═════════════════╕\n",
      "│ \\            │   True (pred) │    False (pred) │\n",
      "╞══════════════╪═══════════════╪═════════════════╡\n",
      "│ True (real)  │          3785 │               0 │\n",
      "├──────────────┼───────────────┼─────────────────┤\n",
      "│ False (Real) │           216 │               0 │\n",
      "╘══════════════╧═══════════════╧═════════════════╛\n",
      "f1 score=0.9723\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(NN_model,test_set=X_test_NN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
