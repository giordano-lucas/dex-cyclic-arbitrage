{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907f511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 22:00:24.633854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "import tensorflow as tf\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "import sys \n",
    "import os\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:4]))\n",
    "from config.get import cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365a4be",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "Predictions will use embeddings produced by the previously selected embeddings model as features. The target variable of the prediction is the boolean value corresponding to the profitability of cycles. The embedding was shuffled when splitting the embedding model training data. Thus, one needs to rematch each embedding with the corresponding target using `cycle_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32c2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features\n",
    "X_train = np.load(cfg['files'][\"liquid\"]['encoded_train_features'])\n",
    "X_test  = np.load(cfg['files'][\"liquid\"]['encoded_test_features'])\n",
    "\n",
    "fX_train = pd.read_csv(cfg['files'][\"liquid\"]['additional_features_train'])\n",
    "fX_test  = pd.read_csv(cfg['files'][\"liquid\"]['additional_features_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e39476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = fX_train.profitability\n",
    "y_test  = fX_test.profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c7af913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9453892668178382\n"
     ]
    }
   ],
   "source": [
    "print(y_train.mean()) # imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bd7311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9538926681783825\n"
     ]
    }
   ],
   "source": [
    "print(y_test.mean()) # imbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eba0f1",
   "metadata": {},
   "source": [
    "# Rescale the features\n",
    "* Embeddings are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62413dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "tX_train = scaler.transform(X_train)\n",
    "tX_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978673e3",
   "metadata": {},
   "source": [
    "# Transform train / test into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6888d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pX_train = pd.DataFrame(data=tX_train, columns=[str(c) for c in range(X_train.shape[1])])\n",
    "pX_test  = pd.DataFrame(data=tX_test,  columns=[str(c) for c in range(X_train.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168348eb",
   "metadata": {},
   "source": [
    "# Token one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee3f6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class TokenEncoding:\n",
    "    def __init__(self):\n",
    "        self.one_enc = OneHotEncoder(sparse=False, handle_unknown = 'ignore') \n",
    "        self.token_columns = ['token1','token2', 'token3']\n",
    "\n",
    "    def fit_tokens(self,data):\n",
    "        unique_tokens = np.unique(pd.concat([data[token] for token in self.token_columns],axis=0))\n",
    "        self.one_enc.fit(unique_tokens.reshape(-1, 1))\n",
    "        return self\n",
    "\n",
    "    def transform_tokens(self,data):\n",
    "        # transform\n",
    "        encode = lambda col: self.one_enc.transform(data[col].to_numpy().reshape(-1, 1))\n",
    "        # encode and convert as dataframes\n",
    "        encoded = [pd.DataFrame(encode(token)).add_prefix(f\"token_{key}_\") for key,token in enumerate(self.token_columns)]\n",
    "        return pd.concat(encoded, axis='columns').astype('float32')\n",
    "    \n",
    "\n",
    "    def join_tokens(self,data, tokens):\n",
    "        if ('token1' in data.columns):\n",
    "            data = data.drop(columns=self.token_columns)\n",
    "        return pd.concat([data,tokens], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7afcdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenEnc = TokenEncoding()\n",
    "tokenEnc.fit_tokens(fX_train)\n",
    "fpX_train = tokenEnc.join_tokens(pX_train, tokenEnc.transform_tokens(fX_train))\n",
    "fpX_test  = tokenEnc.join_tokens(pX_test, tokenEnc.transform_tokens(fX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ca68265d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>token_2_158</th>\n",
       "      <th>token_2_159</th>\n",
       "      <th>token_2_160</th>\n",
       "      <th>token_2_161</th>\n",
       "      <th>token_2_162</th>\n",
       "      <th>token_2_163</th>\n",
       "      <th>token_2_164</th>\n",
       "      <th>token_2_165</th>\n",
       "      <th>token_2_166</th>\n",
       "      <th>token_2_167</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.505291</td>\n",
       "      <td>0.579465</td>\n",
       "      <td>-0.637919</td>\n",
       "      <td>1.917729</td>\n",
       "      <td>-0.471626</td>\n",
       "      <td>-0.269707</td>\n",
       "      <td>-0.487739</td>\n",
       "      <td>0.380295</td>\n",
       "      <td>-0.388063</td>\n",
       "      <td>-0.292947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.862282</td>\n",
       "      <td>0.464563</td>\n",
       "      <td>-0.633860</td>\n",
       "      <td>2.143126</td>\n",
       "      <td>-0.487417</td>\n",
       "      <td>-0.310520</td>\n",
       "      <td>-0.494301</td>\n",
       "      <td>1.236678</td>\n",
       "      <td>-0.266514</td>\n",
       "      <td>-0.230577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573433</td>\n",
       "      <td>-0.535478</td>\n",
       "      <td>-0.576774</td>\n",
       "      <td>-0.489549</td>\n",
       "      <td>-0.454229</td>\n",
       "      <td>2.182124</td>\n",
       "      <td>0.244653</td>\n",
       "      <td>-0.415567</td>\n",
       "      <td>-0.304272</td>\n",
       "      <td>0.855866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643999</td>\n",
       "      <td>-0.542200</td>\n",
       "      <td>-0.564201</td>\n",
       "      <td>-0.490966</td>\n",
       "      <td>-0.448616</td>\n",
       "      <td>2.199132</td>\n",
       "      <td>0.246344</td>\n",
       "      <td>-0.418407</td>\n",
       "      <td>-0.323347</td>\n",
       "      <td>0.821669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.517683</td>\n",
       "      <td>-0.483488</td>\n",
       "      <td>-0.372736</td>\n",
       "      <td>-0.488034</td>\n",
       "      <td>-0.442421</td>\n",
       "      <td>-0.195371</td>\n",
       "      <td>-0.407583</td>\n",
       "      <td>-0.498525</td>\n",
       "      <td>-0.312150</td>\n",
       "      <td>-0.622698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.505291  0.579465 -0.637919  1.917729 -0.471626 -0.269707 -0.487739   \n",
       "1  0.862282  0.464563 -0.633860  2.143126 -0.487417 -0.310520 -0.494301   \n",
       "2  0.573433 -0.535478 -0.576774 -0.489549 -0.454229  2.182124  0.244653   \n",
       "3  0.643999 -0.542200 -0.564201 -0.490966 -0.448616  2.199132  0.246344   \n",
       "4 -0.517683 -0.483488 -0.372736 -0.488034 -0.442421 -0.195371 -0.407583   \n",
       "\n",
       "          7         8         9  ...  token_2_158  token_2_159  token_2_160  \\\n",
       "0  0.380295 -0.388063 -0.292947  ...          0.0          0.0          0.0   \n",
       "1  1.236678 -0.266514 -0.230577  ...          0.0          0.0          0.0   \n",
       "2 -0.415567 -0.304272  0.855866  ...          0.0          0.0          0.0   \n",
       "3 -0.418407 -0.323347  0.821669  ...          0.0          0.0          0.0   \n",
       "4 -0.498525 -0.312150 -0.622698  ...          0.0          0.0          0.0   \n",
       "\n",
       "   token_2_161  token_2_162  token_2_163  token_2_164  token_2_165  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   token_2_166  token_2_167  \n",
       "0          0.0          0.0  \n",
       "1          0.0          0.0  \n",
       "2          0.0          0.0  \n",
       "3          0.0          0.0  \n",
       "4          0.0          0.0  \n",
       "\n",
       "[5 rows x 604 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpX_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2addb79",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e45db8",
   "metadata": {},
   "source": [
    "## model creation & fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8ef2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic(X_train, y_train):\n",
    "    logistic_model = LogisticRegressionCV(\n",
    "        cv=5,\n",
    "        Cs=np.logspace(-4,4,10),\n",
    "        max_iter=5000,\n",
    "        class_weight=\"balanced\")\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "    return logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1415fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = fit_logistic(tX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf78ca",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae8400ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion(tn, fp, fn, tp):\n",
    "    print(f\"True neg : {tn} | False pos : {fp} | False neg : {fn} | True pos : {tp}\")\n",
    "    print(tabulate([['True (real)',tp, fn], ['False (Real)',fp, tn]], headers=['\\\\', 'True (pred)' ,\" False (pred)\"], tablefmt='fancy_grid'))\n",
    "   \n",
    "def evaluate_model(model,test_set):\n",
    "\n",
    "    pred = model.predict(test_set)>0.5\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,pred).ravel()\n",
    "    print_confusion(tn, fp, fn, tp)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    print(f\"f1 score={f1:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ca64a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logistic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22993/1260837429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logistic_model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(logistic_model, test_set=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e4697",
   "metadata": {},
   "source": [
    "## Let's add the token encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d9e0ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True neg : 17 | False pos : 44 | False neg : 378 | True pos : 884\n",
      "╒══════════════╤═══════════════╤═════════════════╕\n",
      "│ \\            │   True (pred) │    False (pred) │\n",
      "╞══════════════╪═══════════════╪═════════════════╡\n",
      "│ True (real)  │           884 │             378 │\n",
      "├──────────────┼───────────────┼─────────────────┤\n",
      "│ False (Real) │            44 │              17 │\n",
      "╘══════════════╧═══════════════╧═════════════════╛\n",
      "f1 score=0.8073\n"
     ]
    }
   ],
   "source": [
    "logistic_model = fit_logistic(fpX_train, y_train)\n",
    "evaluate_model(logistic_model, test_set=fpX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6614c3af",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55523cd8",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b273e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_parameters = {'kernel':('linear', 'rbf','poly'), 'C':np.logspace(-4,4,5)}\n",
    "svc = svm.SVC()\n",
    "svm_model = GridSearchCV(svc, svm_parameters,verbose=1,cv = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee1706",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ca5c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(tX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e8fa",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a17362",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(svm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c2508",
   "metadata": {},
   "source": [
    "# Autoencoder embedding validation\n",
    "In this section we are going to use some ruled based embedding (`build_ruled_based_features/README.md` for more details about the indicators used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "266a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "bX_train = np.load(cfg['files']['liquid']['ruled_based']['scaled_encoded_train_features'])\n",
    "bX_test = np.load(cfg['files']['liquid']['ruled_based']['scaled_encoded_test_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a09774e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "bX_train = bX_train.reshape((bX_train.shape[0],-1))\n",
    "bX_test = bX_test.reshape((bX_test.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ddf5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(bX_train)\n",
    "tbX_train = scaler.transform(bX_train)\n",
    "tbX_test  = scaler.transform(bX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c776e601",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22993/459038759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogistic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "logistic_model = fit_logistic(bX_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bea05ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1242"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(np.unique(pd.read_csv(cfg['files'][\"liquid\"]['ae_test_features']).cycle_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a250439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1323, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758a9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
